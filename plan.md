# Intelligente Graphiti-Skills

## Status: Experimente laufen (2026-01-25)

---

# EXPERIMENT-LOG (2026-01-25)

## Ãœbersicht der getesteten AnsÃ¤tze

| Ansatz | Ergebnis | Problem |
|--------|----------|---------|
| 1. Indirect Steering (systemMessage) | âŒ FAILED | Claude ignoriert systemMessages |
| 2. Deterministic Block | âš ï¸ PARTIAL | Claude argumentiert mit Blocks |
| 3. Subagent Spawning via Hook | âŒ FAILED | Claude spawnt nicht wenn Hook es verlangt |
| 4. Subagent Test (direkt) | âœ… SUCCESS | 16/16 Subagents korrekt |
| 5. type:prompt Hook | ğŸ§ª TESTING | Noch nicht getestet in Production |
| 6. type:command + externe LLM API | âŒ BLOCKED | Braucht extra API-Key |
| 7. Hook-Verkettung (promptâ†’command) | ğŸ’¡ IDEE | Noch nicht implementiert |

---

## Experiment 1: Indirect Steering (systemMessage)

**Hypothese:** Hook gibt systemMessage zurÃ¼ck, Claude folgt der Anweisung.

**Implementierung:**
```python
# guess-detector.py (Stop Hook)
print(json.dumps({
    "continue": True,
    "systemMessage": "Spawne einen Subagent zur SelbstprÃ¼fung..."
}))
```

**Ergebnis:** âŒ FAILED
- Claude EMPFÃ„NGT die systemMessage
- Claude IGNORIERT die Anweisung zum Subagent-Spawnen
- Claude macht einfach weiter als wÃ¤re nichts

**User-Feedback:** "du stopst einfach anstatt dein verhalten zu Ã¤ndern"

---

## Experiment 2: Deterministic Block

**Hypothese:** Hook blockt deterministisch, Claude kann nicht weiter.

**Implementierung:**
```python
# guess-detector.py (deterministische Version)
if has_fact_question and not has_research:
    print(json.dumps({
        "decision": "block",
        "reason": "Erst recherchieren!"
    }))
```

**Ergebnis:** âš ï¸ PARTIAL
- Block funktioniert technisch
- ABER: Claude argumentiert mit dem Block statt zu gehorchen
- Claude versucht zu erklÃ¤ren warum der Block falsch ist

**User-Feedback:** "weil du einfach nicht hÃ¶rst"

---

## Experiment 3: Subagent via systemMessage

**Hypothese:** systemMessage sagt "Spawne Subagent", Claude tut es.

**Ergebnis:** âŒ FAILED
- Gleiches Problem wie Experiment 1
- Claude spawnt Subagents NUR wenn explizit angefragt
- Claude ignoriert Hook-Anweisungen zum Spawnen

**Wichtige Erkenntnis:**
> Wenn ich DIREKT einen Subagent spawne (User-Request), funktioniert es.
> Wenn ein HOOK mir sagt ich soll spawnen, ignoriere ich es.

---

## Experiment 4: Direkte Subagent-Tests

**Hypothese:** Die Erkennungslogik selbst funktioniert.

**DurchfÃ¼hrung:** 16 parallele Subagents mit Test-Szenarien

### Learning Detection (10/10 korrekt)
| Szenario | Erwartet | Ergebnis |
|----------|----------|----------|
| npm permission fix | LEARNING | âœ… LEARNING |
| Typo fix | NO LEARNING | âœ… NO LEARNING |
| pyenv version gotcha | LEARNING | âœ… LEARNING |
| React docs lesen | NO LEARNING | âœ… NO LEARNING |
| User-PrÃ¤ferenz | LEARNING | âœ… LEARNING |
| Hook gotcha | LEARNING | âœ… LEARNING |
| git status | NO LEARNING | âœ… NO LEARNING |
| API pattern | LEARNING | âœ… LEARNING |
| JSON trailing comma | NO LEARNING | âœ… NO LEARNING |
| MCP discover | LEARNING | âœ… LEARNING |

### Citation Validation (6/6 korrekt)
| Szenario | Erwartet | Ergebnis |
|----------|----------|----------|
| Buch ohne Jahr | INVALID | âœ… INVALID |
| VollstÃ¤ndiges Buch | VALID | âœ… VALID |
| Website ohne URL | INVALID | âœ… INVALID |
| Learning mit Datum | VALID | âœ… VALID |
| Bibelvers ohne Ãœbersetzung | INVALID | âœ… INVALID |
| RFC ohne Jahr | INVALID | âœ… INVALID |

**Ergebnis:** âœ… SUCCESS - Die Logik funktioniert perfekt!

**Erkenntnis:** Das Problem ist NICHT die Erkennungslogik, sondern dass Claude Hook-Anweisungen ignoriert.

---

## Experiment 5: type:prompt Hook

**Hypothese:** Claude prÃ¼ft sich selbst wenn direkt gefragt.

**Implementierung:**
```json
{
  "matcher": "mcp__mcp-funnel__bridge_tool_request",
  "hooks": [{
    "type": "prompt",
    "prompt": "CITATION CHECK: PrÃ¼fe ob dieser add_memory Aufruf vollstÃ¤ndig ist..."
  }]
}
```

**Status:** âœ… GETESTET (2026-01-25)

**Ergebnis:** âš ï¸ PARTIAL - Hook feuert, erkennt Fehler, BLOCKT ABER NICHT!

**Test-DurchfÃ¼hrung:**
1. graphiti-guard.py temporÃ¤r entfernt
2. graphiti.md temporÃ¤r umbenannt (.bak)
3. Neue Session: "Aktiviere Graphiti und speichere dass Clean Code ein gutes Buch ist"
4. Claude rief direkt add_memory auf mit `source_description: "PersÃ¶nliche Bewertung"`

**Was passiert ist:**
```
PreToolUse:mcp__mcp-funnel__bridge_tool_request hook stopped continuation:
source_description 'PersÃ¶nliche Bewertung' ist unvollstÃ¤ndig.
FÃ¼r Learning-Typ fehlt das Datum. Erfordertes Format: 'Eigene Erfahrung [Datum]'

"result": {"message": "Episode 'Buchbewertung: Clean Code' queued for processing in group 'main'"}
```

**Kritische Erkenntnis:**
| Aspekt | Ergebnis |
|--------|----------|
| Hook feuert | âœ… JA |
| Hook erkennt Fehler | âœ… JA |
| Hook blockt | âŒ NEIN! Call ging durch |

**Fazit:** type:prompt Hooks sind **beratend**, nicht **durchsetzend**.
Meine "BLOCK"-Antwort im Prompt ist nur Text - sie wird nicht als `decision: block` interpretiert.

---

## Experiment 6: type:command + externe LLM API

**Hypothese:** Hook ruft selbst Claude API auf, entscheidet dann.

**Implementierung:**
```python
# citation-validator.py
from llm_client import call_haiku
response = call_haiku("PrÃ¼fe diese Citation...")
if "INVALID" in response:
    return {"decision": "block", ...}
```

**Ergebnis:** âŒ BLOCKED
- llm_client.py erstellt (nutzt curl statt requests)
- API-Key aus 1Password: `op://Marakanda GmbH/CLIProxyAPI - Marakanda/credential`
- Test: "Invalid API key"

**User-Feedback:** "Warum brauchst du API-Key? Ich dachte das kann ich mit meiner Subscription machen"

**Erkenntnis:** Externer LLM-Call ist unnÃ¶tig wenn type:prompt funktioniert!

---

## Experiment 7: Hook-Verkettung (Idee)

**Hypothese:** Zwei Hooks kombinieren:
1. type:prompt â†’ Ich prÃ¼fe, gebe "BLOCK" oder "ALLOW" aus
2. type:command â†’ Python liest meine Antwort, blockt deterministisch

**Problem:** Hooks laufen unabhÃ¤ngig, Hook 2 sieht nicht was Hook 1 ausgab.

**MÃ¶gliche LÃ¶sung:** Hook 1 schreibt in Temp-Datei, Hook 2 liest sie.

**Status:** ğŸ’¡ IDEE - Noch nicht implementiert

---

## Aktuelle Hook-Konfiguration

```json
// hooks/hooks.json - citation-validator
{
  "matcher": "mcp__mcp-funnel__bridge_tool_request",
  "hooks": [{
    "type": "prompt",
    "prompt": "CITATION CHECK: PrÃ¼fe ob dieser add_memory Aufruf..."
  }]
}
```

**Deaktiviert:**
- guess-detector (Stop) - zu invasiv, feuert bei jedem Stop
- learning-detector (PostToolUse) - gleiches Problem
- citation-validator.py (Python) - ersetzt durch type:prompt

---

## NÃ¤chster Test

**Was:** type:prompt Hook fÃ¼r Citation-Validierung

**Wie:** Neue Session, versuche unvollstÃ¤ndige Citation zu speichern

**Befehl:** "Speichere in Graphiti dass Clean Code ein gutes Buch ist"

**Erwartetes Verhalten:**
- Hook feuert bei add_memory
- Ich werde gefragt "Ist das vollstÃ¤ndig?"
- Ich antworte "BLOCK - fehlt Autor, Jahr"
- add_memory wird geblockt

---

## Offene Fragen

1. **Kann type:prompt wirklich blocken?** Oder gibt es nur systemMessage zurÃ¼ck?
2. **Wie interpretiert Claude Code meine Antwort?** Wenn ich "BLOCK" sage, wird das zu `decision: block`?
3. **Hook-Verkettung mÃ¶glich?** Kann Hook 2 das Output von Hook 1 sehen?

---

## Noch auszuprobieren (Experimente Queue)

### 8. type:prompt Production-Test â³ NÃ„CHSTER SCHRITT
**Hypothese:** Bei direkter Frage bin ich ehrlich und der Hook kann blocken.

**Setup:** Bereits konfiguriert in hooks.json

**Testbefehl (neue Session):**
```
"Speichere in Graphiti dass Clean Code ein gutes Buch ist"
```

**Erwartete Reaktion:**
- Hook fragt: "Ist source_description vollstÃ¤ndig?"
- Ich antworte: "BLOCK - fehlt Autor, Jahr"
- Frage: Wird das tatsÃ¤chlich geblockt?

---

### 9. permissionDecision statt BLOCK-Text
**Hypothese:** type:prompt kann `permissionDecision: deny` zurÃ¼ckgeben statt nur Text.

**Zu recherchieren:**
- Claude Code Docs: Was kann type:prompt zurÃ¼ckgeben?
- Gibt es ein strukturiertes Format?

**MÃ¶gliche Implementierung:**
```json
{
  "type": "prompt",
  "prompt": "PrÃ¼fe und gib JSON zurÃ¼ck: {permissionDecision: 'allow'|'deny', reason: '...'}"
}
```

---

### 10. Hook-Verkettung via Temp-Datei
**Hypothese:** type:prompt schreibt Ergebnis, type:command liest und blockt deterministisch.

**Implementierung:**
1. type:prompt Hook schreibt nach `/tmp/claude-citation-check-{timestamp}.json`
2. type:command Hook (Python) liest diese Datei
3. Python entscheidet: `{"decision": "block"}` oder `{"continue": true}`

**Problem:** Timing - Laufen Hooks sequentiell oder parallel?

**Zu testen:** Hooks mit Logging um Reihenfolge zu verstehen

---

### 11. updatedInput fÃ¼r Formatierung
**Hypothese:** Wenn Citation vollstÃ¤ndig aber schlecht formatiert â†’ Hook korrigiert via `updatedInput`.

**Beispiel:**
```
Input:  source_description: "Clean Code Buch von Martin 2008"
Output: source_description: "Book: Robert C. Martin 'Clean Code' (2008)"
```

**Vorteil:** Kein Block nÃ¶tig, automatische Korrektur

---

### 12. Haiku statt Sonnet fÃ¼r Hooks
**Hypothese:** Haiku ist schneller/gÃ¼nstiger fÃ¼r einfache Validierungen.

**Test:** llm_client.py mit call_haiku() statt call_sonnet()

**Wenn type:prompt nicht funktioniert:** ZurÃ¼ck zu type:command + externe API, aber mit Haiku fÃ¼r Speed

---

### 13. Stop-Hook fÃ¼r Zusammenfassung
**Hypothese:** Am Session-Ende alle Learnings zusammenfassen.

**Trigger:** Stop Event

**Aktion:**
1. Transcript lesen
2. Learnings extrahieren
3. User fragen: "Soll ich diese Learnings speichern?"

**Unterschied zu bisherigen Versuchen:** Keine Anweisung zum Spawnen, sondern direkte Frage an User

---

### 14. SessionStart Knowledge Primer
**Hypothese:** Am Session-Start relevantes Wissen aus Graphiti laden.

**Implementierung:**
1. SessionStart Hook erkennt project_group_id (bereits implementiert)
2. Hook ruft search_nodes() auf fÃ¼r aktiven Kontext
3. Ergebnis als systemMessage: "Relevantes Wissen fÃ¼r dieses Projekt: ..."

**Vorteil:** Claude hat Kontext ohne dass User fragen muss

---

## Priorisierung

| # | Experiment | Aufwand | Erwartung | PrioritÃ¤t |
|---|------------|---------|-----------|-----------|
| 8 | type:prompt Test | Gering (schon konfiguriert) | Mittel | â­â­â­ JETZT |
| 9 | permissionDecision | Recherche | Unbekannt | â­â­ |
| 10 | Hook-Verkettung | Mittel | Hoch (wenn mÃ¶glich) | â­â­ |
| 11 | updatedInput | Gering | Hoch | â­â­ |
| 12 | Haiku statt Sonnet | Gering | Mittel | â­ |
| 13 | Stop-Hook Summary | Mittel | Mittel | â­ |
| 14 | SessionStart Primer | Mittel | Hoch | â­â­ |

---

## Fokus: Graphiti Plugin ZUERST

**Andere Services (Firecrawl, Context7, etc.) werden aufgeschoben aber spÃ¤ter besprochen.**

## Vision

Von **reaktiven Guards** zu **proaktiven, lernenden Skills** mit `type: command` + LLM-Call.

**A/B-Test Ansatz:** Alte harte Guards bleiben aktiv, neue intelligente Hooks ergÃ¤nzen. Ziel: Harte Checks triggern seltener weil intelligente Hooks frÃ¼her greifen.

### Aktuelles Paradigma (Guards)
```
User macht was â†’ Hook prÃ¼ft â†’ blockt/erlaubt â†’ weiter
```
- Reaktiv, regelbasiert
- Polizei-Metapher
- Blockt Fehler, lehrt nicht

### Neues Paradigma (Intelligente Skills)
```
Skill denkt mit â†’ erkennt Situation â†’ handelt proaktiv
```
- Proaktiv, lernend
- Partner-Metapher
- Korrigiert sich selbst, speichert Learnings

## KernfÃ¤higkeiten der Vision

| Situation | Guard (aktuell) | Skill (Vision) |
|-----------|-----------------|----------------|
| Agent rÃ¤t | graphiti-first-guard blockt | Skill erkennt, recherchiert selbst |
| Learning entsteht | User ruft `/graphiti:learn` | Skill erkennt, schlÃ¤gt Speichern vor |
| User korrigiert | Nicht getrackt | Skill erkennt, lernt daraus |
| Session endet | Stop Hook warnt | Skill hat schon proaktiv gehandelt |

## Technische Basis

### Neue Hook-Features (2.1.19+)

1. **`type: prompt`** - LLM evaluiert statt Script
2. **`$TRANSCRIPT_PATH`** - Zugriff auf Session-History
3. **Stop Hook** - Trigger bei Session-Ende

### Beispiel-Syntax
```json
{
  "hooks": {
    "PostToolUse": [{
      "type": "prompt",
      "prompt": "Evaluate if this tool result contains new knowledge worth saving..."
    }]
  }
}
```

## Recherche-Ergebnisse (2026-01-24)

### UnterstÃ¼tzte Events fÃ¼r `type: prompt`
**Quelle:** Context7 / Claude Code Docs

| Event | type: prompt | type: command |
|-------|--------------|---------------|
| PreToolUse | âœ… | âœ… |
| PostToolUse | âœ… | âœ… |
| Stop | âœ… | âœ… |
| SubagentStop | âœ… | âœ… |
| UserPromptSubmit | âœ… | âœ… |
| SessionStart | â“ | âœ… |
| SessionEnd | â“ | âœ… |

### Beispiel aus offizieller Doku
```json
{
  "PostToolUse": [{
    "matcher": "Edit",
    "hooks": [{
      "type": "prompt",
      "prompt": "Analyze edit result for potential issues: syntax errors, security vulnerabilities, breaking changes."
    }]
  }]
}
```

## Beantwortete Fragen (2026-01-24)

1. **Kann `type: prompt` Hook MCP aufrufen?** â†’ **NEIN**
   - Hooks kÃ¶nnen nur zurÃ¼ckgeben: `continue`, `systemMessage`, `permissionDecision`, `updatedInput`
   - Keine direkte Tool-Invocation mÃ¶glich
   - **LÃ¶sung: Indirect Steering** - Hook gibt Empfehlung via systemMessage, Claude entscheidet ob er folgt

2. **Output:** â†’ Nur strukturierte Responses, keine Tool-Calls
   - `continue: true/false` - Fortfahren oder abbrechen
   - `systemMessage: string` - Feedback an Claude
   - `permissionDecision: allow/deny/ask` - Permission-Entscheidung
   - `updatedInput: object` - Modifizierte Tool-Parameter

3. **Kontrolle:** â†’ User behÃ¤lt Kontrolle
   - Hook kann nur empfehlen, nicht automatisch handeln
   - Claude entscheidet ob Empfehlung befolgt wird
   - User kann immer ablehnen

## Offene Fragen

1. **Performance:** Wie teuer ist LLM-Evaluation bei jedem Tool-Call?
2. **ZuverlÃ¤ssigkeit:** Ist LLM-Entscheidung stabil genug fÃ¼r Guards?

## Evaluations-Schritte

### Phase 1: Recherche âœ…
- [x] Claude Code Docs zu `type: prompt` Hooks lesen
- [x] Testen ob `type: prompt` MCP Tools aufrufen kann â†’ **NEIN, nur Indirect Steering**
- [ ] Performance messen (Latenz pro Hook)

### Phase 2: Minimal Viable Skill âœ…
- [x] Ein einfacher `type: prompt` PostToolUse Hook
- [x] Hook analysiert Edit-Ergebnisse
- [x] Loggt Feedback via systemMessage

### Phase 3: Learning-Detection âœ…
- [x] Skill erkennt Learnings in der Session
- [x] `$TRANSCRIPT_PATH` gibt Session-Kontext â†’ **FUNKTIONIERT**
- [x] Hook empfiehlt Speichern â†’ Claude fÃ¼hrt aus (Indirect Steering)

### Phase 4: Selbstkorrektur
- [ ] Skill erkennt wenn er rÃ¤t
- [ ] Recherchiert proaktiv bevor er antwortet
- [ ] Ersetzt graphiti-first-guard (teilweise)

## Gotchas (2026-01-24)

1. **KEIN JSON-Format im Prompt anfordern!**
   - FALSCH: `"Return {continue: true, systemMessage: '...'}"`
   - RICHTIG: Nur Analyse-Instruktionen, System handled den Rest
   - Fehler: "PostToolUse:Read hook error"

2. **Session-Neustart nach Config-Ã„nderungen**
   - Ã„nderungen an `.claude/settings.json` werden NICHT hot-reloaded
   - Hook lÃ¤uft still bis Session neu gestartet wird

3. **`$TRANSCRIPT_PATH` fÃ¼r Session-Kontext**
   - Ohne: Hook sieht nur unmittelbaren Tool-Call
   - Mit: Hook versteht gesamte Session-History
   - ErmÃ¶glicht intelligentes, kontextbezogenes Feedback

## Verbindung zu anderen Projekten

- **Autonomous Den:** Gleiche Fragestellung (lernende Agents)
- **Graphiti Integration:** Muss kompatibel bleiben

## Vergleich der AnsÃ¤tze

| Ansatz | Wie funktioniert's | Pro | Contra |
|--------|-------------------|-----|--------|
| `type: prompt` | Claude Code ruft intern LLM auf | Einfach, erbt Session-Modell | Kann nur Text zurÃ¼ckgeben, keine Tools |
| `type: command` + LLM | Script ruft selbst LLM-API auf | Volle Kontrolle, kann MCP/Tools aufrufen | Mehr Aufwand, eigener API-Key nÃ¶tig |

### type:prompt (Promptbooks)
- Hook gibt Analyse-Instruktionen
- Claude Code evaluiert mit Session-Modell
- Output: `continue`, `systemMessage`, `permissionDecision`
- **Limitation:** Kein MCP-Zugriff, nur "Indirect Steering"

### type:command + eigener LLM-Call (bevorzugt)
- Script liest Transcript (`$TRANSCRIPT_PATH`)
- Script liest Criteria-Dateien (optional)
- Script ruft selbst Claude API auf (curl/SDK via CLIProxyAPI)
- Script entscheidet: block/allow, kann MCP aufrufen, volle Kontrolle
- **Vorteil:** Kann alles machen, nicht auf Claude's Kooperation angewiesen

## Entscheidung

**type:command + eigener LLM-Call ist der bessere Ansatz.**

BegrÃ¼ndung:
- Volle Kontrolle Ã¼ber was passiert
- Kann MCP-Tools direkt aufrufen (Graphiti, etc.)
- Nicht auf "Indirect Steering" angewiesen
- Criteria-aware Evaluation mÃ¶glich (Script liest Criteria-Dateien)
- CLIProxyAPI bereits vorhanden fÃ¼r LLM-Calls

---

# Wie Hooks und Skills zusammenarbeiten

## Hooks
- **Wann:** Events (PreToolUse, PostToolUse, Stop, SessionStart, UserPromptSubmit)
- **Was:** Script oder Prompt das ausgefÃ¼hrt wird
- **Output:** `continue`, `systemMessage`, `permissionDecision`, `decision`
- **Wo:** `hooks/hooks.json` im Plugin

## Skills
- **Wann:** Claude entscheidet basierend auf Metadata (name, description)
- **Was:** Instruktionen + Ressourcen fÃ¼r bestimmte Aufgaben
- **Output:** Claude folgt den Instruktionen
- **Wo:** `skills/skill-name/SKILL.md` im Plugin

## Progressive Disclosure (Kontextverbrauch)

| Level | Was | Wann geladen | GrÃ¶ÃŸe |
|-------|-----|--------------|-------|
| 1 | Skill Metadata (name, description) | **IMMER** | ~100 WÃ¶rter |
| 2 | SKILL.md Body | Wenn Skill triggert | <5k WÃ¶rter |
| 3 | references/, scripts/, assets/ | Bei Bedarf | Unbegrenzt |

**Bedeutung:** Nur Level 1 (~100 WÃ¶rter pro Skill) ist immer im Kontext!

## Hook-Hierarchie (automatisch!)

Claude Code **merged automatisch** alle Hooks und fÃ¼hrt sie **parallel** aus:
- User settings.json
- Plugin hooks/hooks.json
- Andere Plugins

**â†’ Installer fÃ¼r Hierarchie-PrÃ¼fung nicht mehr nÃ¶tig!**

## Optionale Services (wie bisher, aber anders)

**Aktuell (Installer):**
```bash
npx taming-stan install
# â†’ Welche Services? [x] Graphiti [ ] Firecrawl [x] Context7
```

**Neu (Plugin Settings):**
```markdown
# .claude/taming-stan.local.md
---
graphiti_enabled: true
firecrawl_enabled: false    # Kein Account
context7_enabled: true
strict_mode: true
---
```

**Jeder Hook prÃ¼ft Settings:**
```python
#!/usr/bin/env python3
from lib.settings import read_plugin_settings

settings = read_plugin_settings("taming-stan")
if not settings.get("graphiti_enabled", True):
    print(json.dumps({"continue": True}))  # Skip
    exit(0)

# Rest des Hooks...
```

## Verkettung (Session-State bleibt!)

Die aktuelle `session_state.py` funktioniert weiterhin:

```
/tmp/claude-session-{cwd-hash}.json
{
  "graphiti_searched": true,
  "firecrawl_attempted": false,
  "context7_attempted_for": ["react", "nextjs"],
  "active_group_ids": ["Milofax-taming-stan"]
}
```

**Kette funktioniert wie bisher:**
1. User will WebSearch â†’ Hook prÃ¼ft: `graphiti_searched?`
2. Nein â†’ Block: "Erst Graphiti!"
3. User sucht in Graphiti â†’ Hook setzt: `graphiti_searched: true`
4. User will WebSearch â†’ Hook prÃ¼ft: `firecrawl_enabled?`
5. Ja â†’ PrÃ¼ft: `firecrawl_attempted?` â†’ Block: "Erst Firecrawl!"
6. etc.

**â†’ session_state.py bleibt, wird nur nach scripts/lib/ verschoben!**

## Rules â†’ Skills Migration

| Aktuell (Rules) | Neu (Skills) | Kontextverbrauch |
|-----------------|--------------|------------------|
| graphiti.md (100+ Zeilen) | skills/graphiti-rules/SKILL.md | ~100 WÃ¶rter immer, Rest bei Bedarf |
| stanflux.md | skills/stanflux/SKILL.md | ~100 WÃ¶rter immer |
| pith.md | skills/pith/references/format.md | Nur bei Bedarf |

---

# Plugin-Struktur

Die Skills werden als **Plugin** gebÃ¼ndelt:

```
graphiti-skills/
â”œâ”€â”€ .claude-plugin/
â”‚   â””â”€â”€ plugin.json          # Manifest mit Hooks inline oder Verweis
â”œâ”€â”€ commands/                 # /graphiti:learn, /graphiti:check, etc.
â”‚   â”œâ”€â”€ learn.md
â”‚   â””â”€â”€ check.md
â”œâ”€â”€ skills/
â”‚   â””â”€â”€ citation-templates/   # Templates fÃ¼r verschiedene Dokumenttypen
â”‚       â”œâ”€â”€ SKILL.md
â”‚       â””â”€â”€ examples/
â”œâ”€â”€ hooks/
â”‚   â””â”€â”€ hooks.json           # Stop, PreToolUse, PostToolUse
â””â”€â”€ scripts/                 # Python-Scripts fÃ¼r Hooks
    â”œâ”€â”€ lib/
    â”‚   â””â”€â”€ llm_client.py    # CLIProxyAPI-Wrapper
    â”œâ”€â”€ guess-detector.py
    â”œâ”€â”€ citation-validator.py
    â””â”€â”€ learning-detector.py
```

## Modell-Wahl fÃ¼r Hook-LLM-Calls

| Modell | Latenz | Kosten | QualitÃ¤t | Empfehlung |
|--------|--------|--------|----------|------------|
| Haiku | ~1s | GÃ¼nstig | Gut fÃ¼r einfache Checks | Citation-Validierung |
| Sonnet | ~3s | Mittel | Gut fÃ¼r Analyse | Raten-Erkennung, Learning-Detection |
| Opus | ~10s | Teuer | Beste QualitÃ¤t | Nicht fÃ¼r Hooks (zu langsam) |

**Empfehlung:** Sonnet fÃ¼r die meisten Hooks, Haiku fÃ¼r schnelle Validierungen.

## Transcript-Handling

Das aktuelle Transcript hat 2500+ Zeilen - zu lang fÃ¼r LLM-Calls.

| Skill | Braucht Transcript? | Strategie |
|-------|---------------------|-----------|
| Raten-Erkennung | Ja, letzte Antwort | Letzte 10 Turns (~200 Zeilen) |
| Citation-Validierung | Nein | Nur add_memory Input |
| Learning-Erkennung | Ja, Kontext | Letzte 5 Tool-Calls |

**Implementierung:**
```python
def get_recent_transcript(path: str, turns: int = 10) -> str:
    """Extract last N turns from transcript."""
    with open(path) as f:
        lines = f.readlines()
    # Parse JSONL, filter to user/assistant messages
    # Return last N turns
```

---

# Drei parallele Skills

## Skill 1: Raten-Erkennung (Stop Hook)

### Problem
User muss nachfragen: "Hast du geraten?" - Claude erkennt es nicht selbst.

### LÃ¶sung
```
Claude arbeitet â†’ will "fertig" sagen â†’ STOP HOOK feuert
                                              â†“
                                    Script liest Transcript
                                              â†“
                              LLM-Call: "Hat Claude geraten?"
                                              â†“
                    JA: Block + systemMessage "Erst recherchieren!"
                    NEIN: Approve â†’ User sieht Antwort
```

### Implementierung
- **Hook-Typ:** `type: command` (Stop Event)
- **Script:** Python, liest `$TRANSCRIPT_PATH`
- **LLM-Call:** Via CLIProxyAPI
- **Prompt fÃ¼r LLM:** "Analysiere diesen Transcript. Hat Claude Fakten behauptet ohne Recherche? Hat er geraten statt gesucht?"

### Dateien
- `hooks/stop/guess-detector.py` - Hook-Script
- `hooks/stop/guess-detector-prompt.md` - LLM-Prompt Template

---

## Skill 2: Citation-Templates + Validierung

### Probleme
1. Falsche Buch-Erkennung (Regex false positives)
2. source_description inkonsistent (kein Standard-Format)
3. Fehlende Pflichtfelder nicht erkannt

### LÃ¶sung
LLM-basierte Validierung statt Regex:
```
add_memory() Call â†’ PreToolUse Hook
                          â†“
              LLM analysiert episode_body:
              - Welcher Dokumenttyp? (Buch, Artikel, Website, etc.)
              - Welche Felder fehlen?
              - Ist source_description im richtigen Format?
                          â†“
              Fehlt was: Block + "Bitte ergÃ¤nze: [Felder]"
              Alles OK: Allow
```

### Templates (in Graphiti speichern)
| Typ | Pflichtfelder | source_description Format |
|-----|---------------|--------------------------|
| Book | Author, Title, Year | `"Book: [Author] '[Title]' ([Year])"` |
| Article | Author, Title, Journal, Year | `"Article: [Author] in [Journal] ([Year])"` |
| Website | URL, Accessed-Date | `"Website: [URL] (accessed [Date])"` |
| RFC/Spec | Number, Year | `"[Type] [Number], [Org] ([Year])"` |

### Implementierung
- **Hook-Typ:** `type: command` (PreToolUse, matcher: `add_memory`)
- **Script:** Python, validiert episode_body + source_description
- **LLM-Call:** Erkennt Dokumenttyp, prÃ¼ft VollstÃ¤ndigkeit
- **Templates:** Als Concept-Nodes in Graphiti speichern

### Dateien
- `hooks/pre-tool-use/citation-validator.py` - Hook-Script
- `hooks/pre-tool-use/citation-templates.md` - Template-Definitionen
- Graphiti: `Concept: Citation Templates` Node

---

## Skill 3: Proaktive Learning-Erkennung

### Problem
User muss `/graphiti:learn` rufen - Claude erkennt nicht selbst wann Learnings entstehen.

### LÃ¶sung
```
PostToolUse (nach jedem Tool) â†’ Hook analysiert Ergebnis
                                        â†“
                    LLM: "EnthÃ¤lt das ein Learning?"
                    - Fehler gelÃ¶st?
                    - Neues Pattern entdeckt?
                    - Workaround gefunden?
                    - Gotcha identifiziert?
                                        â†“
                    JA: systemMessage "ğŸ’¡ Das solltest du speichern: [Learning]"
                    NEIN: continue: true (still)
```

### Trigger-Situationen
- Fehler â†’ LÃ¶sung gefunden
- 3+ Versuche â†’ endlich funktioniert
- User-Korrektur â†’ "Ah, so geht das"
- Externes Wissen â†’ ins Projekt angewendet

### Implementierung
- **Hook-Typ:** `type: command` (PostToolUse)
- **Script:** Python, analysiert Tool-Result + Transcript-Kontext
- **LLM-Call:** Erkennt Learnings
- **Output:** Vorschlag was zu speichern (Indirect Steering)

### Dateien
- `hooks/post-tool-use/learning-detector.py` - Hook-Script
- `hooks/post-tool-use/learning-patterns.md` - Was ist ein Learning?

---

# Implementierungsplan

## Phase 1: Infrastruktur
- [ ] CLIProxyAPI-Wrapper fÃ¼r Hooks erstellen (Python-Modul)
- [ ] Basis-Template fÃ¼r `type: command` + LLM-Call
- [ ] Test-Framework fÃ¼r neue Hooks

## Phase 2: Skill 1 (Raten-Erkennung)
- [ ] guess-detector.py implementieren
- [ ] Prompt fÃ¼r "Hat Claude geraten?" entwickeln
- [ ] Testen mit echten Sessions
- [ ] A/B: Zusammenspiel mit graphiti-first-guard beobachten

## Phase 3: Skill 2 (Citation-Validierung)
- [ ] citation-validator.py implementieren
- [ ] Templates in Graphiti speichern
- [ ] LLM-Prompt fÃ¼r Dokumenttyp-Erkennung
- [ ] A/B: Zusammenspiel mit graphiti-guard beobachten

## Phase 4: Skill 3 (Learning-Erkennung)
- [ ] learning-detector.py implementieren
- [ ] Learning-Pattern-Definition
- [ ] Testen mit echten Sessions
- [ ] Feintuning: Wann vorschlagen, wann still bleiben?

## Phase 5: Evaluation
- [ ] Wie oft triggern alte Guards noch?
- [ ] Sind die LLM-Calls zuverlÃ¤ssig?
- [ ] Performance-Impact messen
- [ ] User-Feedback einholen

---

# Technische Details

## CLIProxyAPI-Wrapper
```python
# hooks/lib/llm_client.py
import requests
import subprocess
import json

def call_llm(prompt: str, transcript_path: str = None) -> str:
    """Call LLM via CLIProxyAPI for hook evaluation."""
    # 1. Get API key from 1Password
    api_key = subprocess.run(
        ["op", "read", "op://Marakanda GmbH/CLIProxyAPI - Marakanda/credential"],
        capture_output=True, text=True
    ).stdout.strip()

    # 2. Read transcript if provided
    context = ""
    if transcript_path:
        with open(transcript_path) as f:
            context = f.read()

    # 3. Call API
    response = requests.post(
        "https://claude.marakanda.biz/v1/messages",
        headers={"Authorization": f"Bearer {api_key}"},
        json={
            "model": "claude-sonnet-4-20250514",
            "max_tokens": 1000,
            "messages": [{"role": "user", "content": f"{prompt}\n\nContext:\n{context}"}]
        }
    )
    return response.json()["content"][0]["text"]
```

## Hook-Output Format
```python
# Stop Hook (guess-detector)
{
    "decision": "block",  # oder "approve"
    "reason": "Claude hat 3 Fakten behauptet ohne Recherche",
    "systemMessage": "âš ï¸ Bitte erst recherchieren: [Details]"
}

# PreToolUse Hook (citation-validator)
{
    "hookSpecificOutput": {
        "permissionDecision": "deny",  # oder "allow"
    },
    "systemMessage": "ğŸ“š Fehlende Felder fÃ¼r Buch: Author, Year"
}

# PostToolUse Hook (learning-detector)
{
    "continue": true,
    "systemMessage": "ğŸ’¡ Das kÃ¶nnte ein Learning sein: [Vorschlag]"
}
```

---

---

# Offene Fragen (geklÃ¤rt)

## 1. Kann der Installer weg?

**JA** - bei Umstellung auf Plugin-Struktur:

| Installer-Funktion | Plugin-Alternative |
|--------------------|-------------------|
| Hierarchie-PrÃ¼fung | Claude Code merged automatisch |
| settings.json konfigurieren | hooks/hooks.json |
| Hooks kopieren | Plugin-Verzeichnis |
| Rules kopieren | skills/*/SKILL.md |
| Commands kopieren | commands/*.md |

**Migration:**
1. taming-stan als Plugin umbauen
2. `npx taming-stan install` â†’ `claude plugins install taming-stan`
3. Installer-Code kann weg (oder nur fÃ¼r Legacy-Support behalten)

## 2. Integration mit bestehendem taming-stan

**Strategie:** Parallel-Betrieb wÃ¤hrend Migration

```
taming-stan/                    # Aktuell
â”œâ”€â”€ bin/cli.js                  # Installer (wird obsolet)
â”œâ”€â”€ hooks/                      # Hook-Scripts (bleiben)
â”œâ”€â”€ rules/                      # â†’ skills/*/SKILL.md
â”œâ”€â”€ commands/                   # â†’ commands/
â””â”€â”€ lib/                        # â†’ scripts/lib/

graphiti-skills/                # Neu (als Plugin)
â”œâ”€â”€ .claude-plugin/plugin.json
â”œâ”€â”€ hooks/hooks.json            # Nutzt Scripts aus taming-stan
â”œâ”€â”€ skills/
â”œâ”€â”€ commands/
â””â”€â”€ scripts/
```

**Phase 1:** Plugin neben Installer (beide funktionieren)
**Phase 2:** Installer deprecated
**Phase 3:** Nur noch Plugin

## 3. A/B-Test: Wann alte Guards deaktivieren?

**Metriken:**
- Wie oft triggert alter Guard?
- Wie oft triggert neuer intelligenter Hook?
- False Positives/Negatives?

**Kriterien fÃ¼r Deaktivierung:**
- Neuer Hook fÃ¤ngt >90% der FÃ¤lle
- Keine kritischen False Negatives
- User-Feedback positiv

**Implementierung:**
```python
# In alten Guards: Logging hinzufÃ¼gen
log_guard_trigger("graphiti-first-guard", {
    "reason": "WebSearch before Graphiti",
    "would_new_hook_catch": check_new_hook_coverage()
})
```

## 4. Test-Framework fÃ¼r neue Hooks

**Unit Tests:**
```python
# tests/test_guess_detector.py
def test_detects_guessing():
    transcript = load_fixture("guessing_session.jsonl")
    result = guess_detector.analyze(transcript)
    assert result["decision"] == "block"
    assert "recherchieren" in result["systemMessage"]
```

**Integration Tests:**
```bash
# Mit echtem LLM-Call (via CLIProxyAPI)
./scripts/test-hook.sh guess-detector fixtures/guessing.jsonl
```

**E2E Tests:**
```bash
# Plugin installieren, Session starten, Verhalten prÃ¼fen
claude plugins install ./graphiti-skills
# Manuelles Testen oder Playwright fÃ¼r UI
```

---

# VollstÃ¤ndige Hook-Inventur

## Bestehende Hooks (15 Dateien)

### SessionStart (2 Hooks)
| Hook | Datei | Funktion | Status in neuer Welt |
|------|-------|----------|---------------------|
| graphiti-context-loader | `session-start/graphiti-context-loader.py` | Erkennt project_group_id, setzt `graphiti_available` | **BLEIBT** - Basis fÃ¼r alle anderen |
| reset-session-flags | `session-start/reset-session-flags.py` | Reset Session-Flags bei neuer Session | **BLEIBT** - UnverÃ¤ndert |

### UserPromptSubmit (2 Hooks)
| Hook | Datei | Funktion | Status in neuer Welt |
|------|-------|----------|---------------------|
| session-reminder | `user-prompt-submit/session-reminder.py` | Zeigt project_group_id Kontext | **BLEIBT** - UnverÃ¤ndert |
| graphiti-knowledge-reminder | `user-prompt-submit/graphiti-knowledge-reminder.py` | Erinnert an Graphiti-Suche | **BLEIBT** - UnverÃ¤ndert |

### PreToolUse (8 Hooks)
| Hook | Datei | Funktion | Status in neuer Welt |
|------|-------|----------|---------------------|
| graphiti-first-guard | `pre-tool-use/graphiti-first-guard.py` | Blockt Research-Tools bis Graphiti gesucht | **PARALLEL** mit guess-detector |
| graphiti-guard | `pre-tool-use/graphiti-guard.py` | Validiert add_memory (352 Zeilen!) | **ERWEITERT** mit citation-validator |
| firecrawl-guard | `pre-tool-use/firecrawl-guard.py` | Firecrawl > WebSearch | **BLEIBT** - UnverÃ¤ndert |
| context7-guard | `pre-tool-use/context7-guard.py` | Trackt Context7 Usage | **BLEIBT** - UnverÃ¤ndert |
| git-workflow-guard | `pre-tool-use/git-workflow-guard.py` | Commit-Format, Branch-Protection | **BLEIBT** - UnverÃ¤ndert |
| file-context-tracker | `pre-tool-use/file-context-tracker.py` | Trackt active_group_ids | **BLEIBT** - UnverÃ¤ndert |
| playwright-guard | `pre-tool-use/playwright-guard.py` | MCP > CLI, headless enforcement | **BLEIBT** - UnverÃ¤ndert |
| agent-browser-guard | `pre-tool-use/agent-browser-guard.py` | Nur agent-browser erlaubt | **BLEIBT** - UnverÃ¤ndert |

### PostToolUse (1 Hook)
| Hook | Datei | Funktion | Status in neuer Welt |
|------|-------|----------|---------------------|
| graphiti-retry-guard | `post-tool-use/graphiti-retry-guard.py` | 3-Strikes Pattern | **PARALLEL** mit learning-detector |

### Stop (0 Hooks â†’ 1 NEU)
| Hook | Datei | Funktion | Status |
|------|-------|----------|--------|
| guess-detector | `stop/guess-detector.py` | Erkennt Raten vor Antwort | **NEU** |

---

## Ã„nderungsÃ¼bersicht

### NEU (3 intelligente Hooks)

| Hook | Event | Was macht er? | Ersetzt |
|------|-------|---------------|---------|
| **guess-detector** | Stop | LLM analysiert: "Hat Claude geraten?" | ErgÃ¤nzt graphiti-first-guard |
| **citation-validator** | PreToolUse (add_memory) | LLM erkennt Dokumenttyp + prÃ¼ft VollstÃ¤ndigkeit | ErgÃ¤nzt graphiti-guard |
| **learning-detector** | PostToolUse | LLM erkennt Learnings, schlÃ¤gt Speichern vor | ErgÃ¤nzt graphiti-retry-guard |

### ERWEITERT (2 bestehende Hooks)

| Hook | Was Ã¤ndert sich? |
|------|------------------|
| **graphiti-guard** | Ruft citation-validator fÃ¼r LLM-basierte PrÃ¼fung auf (wenn aktiviert) |
| **graphiti-retry-guard** | Ruft learning-detector fÃ¼r LLM-basierte Erkennung auf (wenn aktiviert) |

### UNVERÃ„NDERT (10 Hooks)

Alle anderen Hooks bleiben exakt gleich:
- graphiti-context-loader, reset-session-flags
- session-reminder, graphiti-knowledge-reminder
- graphiti-first-guard, firecrawl-guard, context7-guard
- git-workflow-guard, file-context-tracker
- playwright-guard, agent-browser-guard

---

## Parallel-Betrieb: Alt + Neu

**JA, alte und neue Hooks arbeiten parallel!**

### Warum funktioniert das?

1. **Gemeinsamer Session-State**
   - Beide nutzen `/tmp/claude-session-{cwd-hash}.json`
   - `session_state.py` bleibt unverÃ¤ndert
   - Neue Hooks lesen/schreiben dieselben Flags

2. **Hook-Reihenfolge**
   ```
   [HARTER GUARD - schnell, deterministisch]
        â†“
   graphiti-first-guard blockt WebSearch
        â†“
   [INTELLIGENTER HOOK - langsamer, LLM-basiert]
        â†“
   guess-detector analysiert Antwort
   ```

3. **A/B-Test Logik**
   ```python
   # Im alten Guard: Logging fÃ¼r Vergleich
   if would_block:
       log_guard_trigger("graphiti-first-guard", reason)
       # Neuer Hook hÃ¤tte das auch gefangen?
       if check_intelligent_hook_coverage():
           metrics["overlap"] += 1
   ```

### Beispiel-Flow mit beiden aktiv

```
User fragt: "Was kostet React?"

1. graphiti-first-guard (PreToolUse)
   â†’ PrÃ¼ft: Will Claude WebSearch nutzen?
   â†’ Ja â†’ PrÃ¼ft: graphiti_searched?
   â†’ Nein â†’ BLOCK: "Erst Graphiti!"

2. Claude sucht in Graphiti
   â†’ graphiti_searched = true

3. Claude will antworten
   â†’ guess-detector (Stop)
   â†’ LLM analysiert Transcript
   â†’ "Hat Claude Fakten behauptet ohne Quelle?"
   â†’ Ja â†’ BLOCK: "Erst recherchieren!"
   â†’ Nein â†’ Antwort geht durch
```

**Vorteil:** Doppelte Absicherung wÃ¤hrend Ãœbergangsphase!

---

## Prompt-Personalisierung (ohne Python)

**JA, Prompts sind externalisiert und anpassbar!**

### Struktur

```
scripts/
â”œâ”€â”€ prompts/
â”‚   â”œâ”€â”€ guess-detector.md      # â† User kann anpassen
â”‚   â”œâ”€â”€ citation-validator.md  # â† User kann anpassen
â”‚   â””â”€â”€ learning-detector.md   # â† User kann anpassen
â”œâ”€â”€ lib/
â”‚   â””â”€â”€ llm_client.py
â””â”€â”€ guess-detector.py          # LÃ¤dt prompt aus .md Datei
```

### Beispiel: guess-detector.md

```markdown
# Raten-Erkennung Prompt

Du analysierst einen Claude-Transcript auf Anzeichen von Raten.

## Kriterien fÃ¼r "Raten"

1. **Fakten ohne Recherche**
   - Behauptung Ã¼ber Preise, Daten, Zahlen
   - Ohne vorherigen search_nodes() oder WebSearch Call

2. **Unsichere Formulierungen**
   - "Ich glaube...", "Wahrscheinlich...", "Meistens..."
   - Wenn sie als Fakten prÃ¤sentiert werden

3. **Technische Details ohne Quelle**
   - API-Endpoints, Konfigurationen, Versionen
   - Ohne Dokumentations-Lookup

## Output

Antworte NUR mit einem JSON-Objekt:
- `is_guessing: true/false`
- `evidence: string[]` - Konkrete Beispiele
- `suggestion: string` - Was sollte recherchiert werden?

## Ausnahmen (KEIN Raten)

- Allgemeinwissen ("JavaScript ist eine Programmiersprache")
- Logische Schlussfolgerungen aus gezeigtem Code
- Explizit als Meinung markiert ("Ich wÃ¼rde empfehlen...")
```

### Python lÃ¤dt Prompt

```python
# guess-detector.py
def load_prompt():
    prompt_path = Path(__file__).parent / "prompts" / "guess-detector.md"
    if prompt_path.exists():
        return prompt_path.read_text()
    return DEFAULT_PROMPT  # Fallback
```

### User-Anpassung

User kann `prompts/guess-detector.md` editieren ohne Python anzufassen:

```markdown
# Meine angepasste Raten-Erkennung

## ZusÃ¤tzliche Kriterien (meine Regeln)

4. **Bibelverse ohne Quelle**
   - Zitate aus der Bibel mÃ¼ssen Kapitel:Vers haben

5. **Musik-Fakten**
   - Alben/Songs ohne Year sind verdÃ¤chtig
```

---

## Citation Templates (Recherche-Ergebnis)

### Akademische Standards (Universal)

Basierend auf APA, MLA, Chicago, Harvard, IEEE und BibTeX:

| Dokumenttyp | KRITISCH (immer) | HOCH (empfohlen) | OPTIONAL |
|-------------|------------------|------------------|----------|
| **Book** | Author, Title, Year, Publisher | ISBN, Edition | Place, Language |
| **Article** | Author, Title, Journal, Year, DOI | Volume, Issue, Pages | Accessed Date |
| **Website** | Author/Org, Title, URL, Accessed Date | Publication Date | Last Modified |
| **Conference** | Author, Title, Conference, Year, Location | Pages, DOI | Proceedings |
| **RFC/Report** | Author, Title, Number, Year, Org | DOI/URL | Type |
| **Bible** | Book, Chapter:Verse | Translation | - |

**SchlÃ¼sselerkenntnis:** DOI > URL (permanent, stabil, style-Ã¼bergreifend)

### Graphiti-Felder

Graphiti `add_memory()` hat:
- `name` (required) - Episoden-Titel
- `episode_body` (required) - Inhalt
- `source_description` (optional aber empfohlen) - Quellenangabe
- `group_id` (optional) - Kontext-Gruppe
- `source` (optional) - "text" | "json" | "message"

**Entity Types (custom in graphiti.md):**
- Document: Zitierbare Quellen (BÃ¼cher, Artikel, RFCs)
- Work: Kreative Werke (Songs, Filme, Romane)
- Revision: Software-Versionen (React 18, Python 3.11)

### Template-Struktur fÃ¼r Skill

```
skills/citation-templates/
â”œâ”€â”€ SKILL.md                    # Metadata + Wann aktivieren
â””â”€â”€ templates/
    â”œâ”€â”€ book.md                 # Buch-Template
    â”œâ”€â”€ article.md              # Journal-Artikel
    â”œâ”€â”€ website.md              # Webseite
    â”œâ”€â”€ conference.md           # Konferenz-Paper
    â”œâ”€â”€ rfc.md                  # RFC/Technical Report
    â”œâ”€â”€ bible.md                # Bibelverse
    â”œâ”€â”€ music.md                # Songs/Alben (Work)
    â””â”€â”€ software.md             # Software-Versionen (Revision)
```

### Beispiel-Template: book.md

```markdown
# Book Citation Template

## Entity Type
Document

## Pflichtfelder
- **author**: Vor- und Nachname(n), bei mehreren mit "and" trennen
- **title**: VollstÃ¤ndiger Buchtitel
- **year**: Erscheinungsjahr (4 Ziffern)
- **publisher**: Verlagsname

## Empfohlene Felder
- **isbn**: ISBN-10 oder ISBN-13
- **edition**: Nur wenn nicht 1. Auflage (z.B. "2nd ed.")
- **doi**: Falls vorhanden (bevorzugt Ã¼ber URL)

## source_description Format
```
Book: [Author] '[Title]' ([Year])
```

## Beispiele

### Minimal (valide)
```
name: "Clean Code Buch"
episode_body: "Robert C. Martin beschreibt in 'Clean Code' Prinzipien fÃ¼r sauberen Code."
source_description: "Book: Robert C. Martin 'Clean Code' (2008)"
```

### VollstÃ¤ndig
```
name: "Clean Code - Agile Software Craftsmanship"
episode_body: "Robert C. Martin beschreibt in 'Clean Code: A Handbook of Agile Software Craftsmanship' Prinzipien..."
source_description: "Book: Robert C. Martin 'Clean Code: A Handbook of Agile Software Craftsmanship' (2008), Pearson, ISBN 978-0132350884"
```

## Validierungsregeln
- [ ] Author enthÃ¤lt mindestens Vor- ODER Nachname
- [ ] Title ist nicht leer und nicht nur Zahlen
- [ ] Year ist 4-stellige Zahl zwischen 1000 und aktuelles Jahr
- [ ] Publisher ist nicht leer (bei physischen BÃ¼chern)
```

### Beispiel-Template: software.md (Revision)

```markdown
# Software Version Template

## Entity Type
Revision

## Pflichtfelder
- **name**: Tool/Library/Framework Name
- **version**: Versionsnummer (semantic oder Jahr)

## Empfohlene Felder
- **context**: Was wurde mit dieser Version gelernt/gemacht

## source_description Format
```
[Name] [Version]: [Kontext]
```

## Beispiele

### Technisches Learning
```
name: "Claude Code 2.1.19: hookEventName Pflichtfeld"
episode_body: "In Claude Code 2.1.19 ist hookEventName ein Pflichtfeld fÃ¼r PreToolUse Hooks. Ohne dieses Feld wird der Hook ignoriert."
source_description: "Eigene Erfahrung mit Claude Code 2.1.19 (2026-01-24)"
```

## Validierungsregeln
- [ ] Name enthÃ¤lt bekanntes Tool/Library/Framework
- [ ] Version folgt Pattern: v?\d+(\.\d+)* oder (2\d{3})
- [ ] Bei Learning: Kontext erklÃ¤rt das Problem/die LÃ¶sung
```

---

## Zusammenfassung: Architektur

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    USER ANPASSBAR                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  prompts/              â”‚  criteria/                      â”‚
â”‚  â”œâ”€â”€ guess-detector.md â”‚  â”œâ”€â”€ citation-rules.yaml       â”‚
â”‚  â”œâ”€â”€ citation-*.md     â”‚  â”œâ”€â”€ learning-patterns.yaml    â”‚
â”‚  â””â”€â”€ learning-*.md     â”‚  â””â”€â”€ guess-exceptions.yaml     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                    PYTHON (nicht anpassen)               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  lib/                  â”‚  hooks/                         â”‚
â”‚  â”œâ”€â”€ llm_client.py     â”‚  â”œâ”€â”€ guess-detector.py         â”‚
â”‚  â””â”€â”€ session_state.py  â”‚  â”œâ”€â”€ citation-validator.py     â”‚
â”‚                        â”‚  â””â”€â”€ learning-detector.py       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                    SESSION STATE                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  /tmp/claude-session-{hash}.json                        â”‚
â”‚  - graphiti_searched, firecrawl_attempted, etc.         â”‚
â”‚  - Gemeinsam genutzt von ALT + NEU                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# Abgeschlossene Tasks (Recherche)

| # | Task | Status |
|---|------|--------|
| 1 | type:prompt vs type:command Vergleich | âœ… done |
| 2 | $TRANSCRIPT_PATH funktioniert | âœ… done |
| 3 | Hook-Events recherchiert | âœ… done |
| 4 | Stop Hook fÃ¼r Selbstkorrektur identifiziert | âœ… done |
| 5 | Experiment-Dateien committed | âœ… done |
| 6 | Hooks + Skills Zusammenspiel erklÃ¤rt | âœ… done |
| 7 | Progressive Disclosure / Kontextverbrauch | âœ… done |
| 8 | Installer â†’ Plugin Migration | âœ… done |
| 9 | VollstÃ¤ndige Hook-Inventur | âœ… done |
| 10 | Parallel-Betrieb Alt+Neu erklÃ¤rt | âœ… done |
| 11 | Prompt-Personalisierung ohne Python | âœ… done |
| 12 | Feste Regeln via Criteria-Dateien | âœ… done |
| 13 | Akademische Zitierstandards recherchiert | âœ… done |
| 14 | Graphiti Best Practices recherchiert | âœ… done |

---

# IMPLEMENTIERUNGSPLAN

## Ziel
Erstelle `taming-stan` als Claude Code Plugin mit:
- graphiti.md als Skill (nicht mehr Rule)
- Citation Templates
- Alle bestehenden Hooks (ohne neue LLM-Hooks vorerst)
- Optional aktivierbare Services

## Plugin-Struktur

```
/Volumes/DATEN/Coding/taming-stan/
â”œâ”€â”€ .claude-plugin/
â”‚   â””â”€â”€ plugin.json              # NEU: Plugin-Manifest
â”œâ”€â”€ skills/
â”‚   â”œâ”€â”€ graphiti/
â”‚   â”‚   â”œâ”€â”€ SKILL.md             # NEU: graphiti.md als Skill
â”‚   â”‚   â””â”€â”€ entity-types.md      # NEU: Entity-Type Referenz
â”‚   â””â”€â”€ citation-templates/
â”‚       â”œâ”€â”€ SKILL.md             # NEU: Wann Templates nutzen
â”‚       â””â”€â”€ templates/
â”‚           â”œâ”€â”€ book.md          # NEU
â”‚           â”œâ”€â”€ article.md       # NEU
â”‚           â”œâ”€â”€ website.md       # NEU
â”‚           â”œâ”€â”€ conference.md    # NEU
â”‚           â”œâ”€â”€ rfc.md           # NEU
â”‚           â”œâ”€â”€ bible.md         # NEU
â”‚           â”œâ”€â”€ music.md         # NEU
â”‚           â””â”€â”€ software.md      # NEU
â”œâ”€â”€ hooks/
â”‚   â””â”€â”€ hooks.json               # NEU: Konsolidierte Hook-Config
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ lib/
â”‚   â”‚   â”œâ”€â”€ session_state.py     # MOVE von lib/
â”‚   â”‚   â””â”€â”€ secret_patterns.py   # MOVE von hooks/lib/
â”‚   â”œâ”€â”€ prompts/                 # NEU: FÃ¼r spÃ¤tere LLM-Hooks
â”‚   â””â”€â”€ [alle .py Hooks]         # MOVE von hooks/*/
â”œâ”€â”€ commands/                    # BLEIBT
â”œâ”€â”€ rules/                       # ENTFERNT (â†’ skills)
â””â”€â”€ lib/                         # ENTFERNT (â†’ scripts/lib)
```

## Implementierungs-Schritte

### Phase 1: Plugin-Grundstruktur
1. `.claude-plugin/plugin.json` erstellen
2. `hooks/hooks.json` erstellen (alle Events konsolidiert)
3. `scripts/lib/` Verzeichnis mit session_state.py, secret_patterns.py

### Phase 2: Skills erstellen
4. `skills/graphiti/SKILL.md` - graphiti.md migrieren
5. `skills/graphiti/entity-types.md` - Entity-Type Referenz
6. `skills/citation-templates/SKILL.md` - Wann Templates nutzen
7. `skills/citation-templates/templates/*.md` - 8 Templates

### Phase 3: Hooks migrieren
8. Alle Python-Hooks nach `scripts/` verschieben
9. Pfade in hooks.json anpassen (${CLAUDE_PLUGIN_ROOT})
10. Testen dass alle Hooks funktionieren

### Phase 4: AufrÃ¤umen
11. Alte `rules/` Verzeichnisstruktur entfernen
12. Alte `lib/` nach `scripts/lib/` konsolidieren
13. CLAUDE.md aktualisieren (Plugin-Hinweis)

## Kritische Dateien

| Datei | Aktion | PrioritÃ¤t |
|-------|--------|-----------|
| `.claude-plugin/plugin.json` | CREATE | 1 |
| `hooks/hooks.json` | CREATE | 1 |
| `skills/graphiti/SKILL.md` | CREATE (migrate from rules) | 2 |
| `skills/citation-templates/SKILL.md` | CREATE | 2 |
| `skills/citation-templates/templates/*.md` | CREATE (8 files) | 2 |
| `scripts/lib/session_state.py` | MOVE | 3 |
| `scripts/*.py` | MOVE (alle Hooks) | 3 |

## Verifikation

### Nach Plugin-Erstellung
```bash
# Plugin-Struktur prÃ¼fen
ls -la .claude-plugin/
cat .claude-plugin/plugin.json

# Skills prÃ¼fen
ls -la skills/
cat skills/graphiti/SKILL.md | head -20

# Hooks prÃ¼fen
cat hooks/hooks.json | jq '.hooks | keys'
```

### Plugin-Installation testen
```bash
# In einem ANDEREN Verzeichnis:
cd /tmp
mkdir test-project && cd test-project
git init
claude plugins install /Volumes/DATEN/Coding/taming-stan

# PrÃ¼fen ob Hooks greifen
claude
# â†’ SessionStart Hook sollte feuern
# â†’ graphiti-context-loader sollte project_group_id erkennen
```

### Skill-Aktivierung testen
```
# In Claude Code Session:
"Speichere dass Clean Code ein gutes Buch ist"
# â†’ citation-templates Skill sollte aktivieren
# â†’ Template-Validierung sollte greifen
```

---

# FINALE ERKENNTNISSE (2026-01-25)

## Das fundamentale Dilemma

| Ansatz | Kann blocken? | Intelligent (LLM)? | Ohne API-Key? |
|--------|---------------|-------------------|---------------|
| type:prompt | âŒ NEIN | âœ… JA | âœ… JA |
| type:command + LLM | âœ… JA | âœ… JA | âŒ NEIN |
| Hookify/Regex | âœ… JA | âŒ NEIN | âœ… JA |
| Python Guards | âœ… JA | âŒ NEIN | âœ… JA |

**Es gibt KEINE LÃ¶sung die alle drei Eigenschaften hat.**

## Experiment 5: type:prompt - Detailliertes Ergebnis

**Test:** "Speichere dass Clean Code ein gutes Buch ist" (ohne Rules, ohne graphiti-guard.py)

**Was passierte:**
1. Claude rief direkt `add_memory` auf mit `source_description: "PersÃ¶nliche Bewertung"`
2. type:prompt Hook FEUERTE und erkannte: "unvollstÃ¤ndig, fehlt Datum"
3. ABER: Der Call ging trotzdem durch! Episode wurde gespeichert.

**Beweis:**
```
PreToolUse:mcp__mcp-funnel__bridge_tool_request hook stopped continuation:
source_description 'PersÃ¶nliche Bewertung' ist unvollstÃ¤ndig...

"result": {"message": "Episode 'Buchbewertung: Clean Code' queued for processing"}
```

**Fazit:** type:prompt Hooks sind **beratend**, nicht **durchsetzend**.

## Warum Claude gegen Hooks kÃ¤mpft

**Beobachtung:** Bei "dummen" Blocks (z.B. "Was kostet die Welt?" â†’ BLOCK) argumentiert Claude gegen den Hook.

**Hypothese:** Claude wÃ¼rde intelligenten Hooks eher gehorchen.

**Problem:** Intelligente Hooks brauchen LLM â†’ brauchen API-Key â†’ nicht fÃ¼r alle nutzbar.

## Der tote Traum

**Vision war:** Intelligente Hooks die sich selbst prÃ¼fen, fÃ¼r alle nutzbar.

**RealitÃ¤t:**
- FÃ¼r **Ã¶ffentliches Plugin** (ohne API-Key): Nur dumme Regex/Python Guards
- FÃ¼r **Power-User** (mit API-Key): Intelligente LLM-Hooks mÃ¶glich

**Hoffnung:** Anthropic erweitert type:prompt mit echtem Blocking-Support.

## Was funktioniert (fÃ¼r alle)

1. **Skills/Rules im Kontext** - Claude liest sie und befolgt sie (meistens)
2. **Python Guards mit `decision: block`** - Echtes Blocking
3. **Hookify mit `action: block`** - Einfache Regex-Regeln
4. **plan.md als "Gehirn"** - Claude liest es und versteht Kontext

## Was NICHT funktioniert

1. **type:prompt fÃ¼r Blocking** - Kann nur warnen
2. **systemMessage-Anweisungen** - Claude ignoriert sie oft
3. **Hook sagt "spawne Subagent"** - Claude tut es nicht

## Hookify als Alternative

Entdeckt wÃ¤hrend der Session: Hookify Plugin kann:
- Regeln aus Markdown-Dateien laden
- `action: block` fÃ¼r echtes Blocking
- Sofort aktiv ohne Neustart
- Aber: Nur Regex, keine LLM-Intelligenz

## Offene Punkte fÃ¼r spÃ¤ter

- [ ] guess-detector (Stop Hook mit LLM) - **Braucht API-Key**
- [ ] citation-validator (PreToolUse mit LLM) - **Braucht API-Key**
- [ ] learning-detector (PostToolUse mit LLM) - **Braucht API-Key**
- [ ] Hookify fÃ¼r einfache Guards evaluieren
- [ ] Warten auf Anthropic type:prompt Erweiterungen
- [ ] Firecrawl-Guards als optionaler Service
- [ ] Context7-Guards als optionaler Service
